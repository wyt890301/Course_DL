{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ac505d-8c4a-4bf4-848d-ceffbcbe8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d799c2c-ad0c-46c8-8497-580aafe916f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 111\n",
    "BATCH_SIZE = 500\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0d273f-a5c5-4ec0-97b6-4c43d930f5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料共63325筆\n",
      "驗證資料共450筆\n",
      "測試資料共450筆\n"
     ]
    }
   ],
   "source": [
    "dir_path = '../data/'\n",
    "\n",
    "train, train_labels = [], []\n",
    "with open(dir_path + 'train.txt', 'r') as f:\n",
    "  for line in f:\n",
    "    data = line.split(\" \")\n",
    "    train.append(dir_path + data[0])\n",
    "    train_labels.append(data[1].replace('\\n', ''))\n",
    "\n",
    "\n",
    "val, val_labels = [], []\n",
    "with open(dir_path + 'val.txt', 'r') as f:\n",
    "  for line in f:\n",
    "    data = line.split(\" \")\n",
    "    val.append(dir_path + data[0])\n",
    "    val_labels.append(data[1].replace('\\n', ''))\n",
    "\n",
    "\n",
    "test, test_labels = [], []\n",
    "with open(dir_path + 'test.txt', 'r') as f:\n",
    "  for line in f:\n",
    "    data = line.split(\" \")\n",
    "    test.append(dir_path + data[0])\n",
    "    test_labels.append(data[1].replace('\\n', ''))\n",
    "\n",
    "print(f'訓練資料共{len(train)}筆')\n",
    "print(f'驗證資料共{len(val)}筆')\n",
    "print(f'測試資料共{len(test)}筆')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a541efc-9d00-4379-b6d8-d8ebdfa4515c",
   "metadata": {},
   "source": [
    "### 資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca6ae47-54d8-49d2-abc0-155a15370568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(paths):\n",
    "    features = []\n",
    "    for path in tqdm(paths):\n",
    "        # 讀取image，並轉為灰階影像\n",
    "        img = cv2.imread(path, 0)\n",
    "        img = cv2.resize(img, (32, 32))\n",
    "        # 標準化(MaxAbs)，灰階影像最大為255\n",
    "        img = img / 255\n",
    "        features.append(img)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a881e2f-b6da-451f-9525-3f7724ef6c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d17324a74684d948e84751a530b83cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab97a20a8fc84370bfaf0c38a55f5edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c771756440f4146bae48f99ee0c07df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.3 s, sys: 3.13 s, total: 37.4 s\n",
      "Wall time: 42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_features = data_preprocess(train)\n",
    "val_features = data_preprocess(val)\n",
    "test_features = data_preprocess(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4bdf81-8244-4aeb-80c9-aa306e367da9",
   "metadata": {},
   "source": [
    "### OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "117081c8-8501-4d3c-b064-2e13a778c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轉成np.array再轉成oneHotEncoding\n",
    "def OneHotEncoding(labels):\n",
    "    return np.eye(50)[np.array(list(map(int, labels)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a34aae-8708-404e-a8de-1c1ab0f89e4b",
   "metadata": {},
   "source": [
    "### shuffle tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecf7eb71-89f0-4dfa-a35f-c00c509813b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x, y):\n",
    "    index = np.arange(x.shape[0])\n",
    "    np.random.shuffle(index)\n",
    "    return x[index], y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "086b222c-f3b5-457e-aa7a-d671d63135af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = shuffle(np.array(train_features), OneHotEncoding(train_labels))\n",
    "X_val, Y_val = shuffle(np.array(val_features), OneHotEncoding(val_labels))\n",
    "X_test, Y_test = shuffle(np.array(test_features), OneHotEncoding(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53c531c-d773-4ace-ab45-6b8a1df8b0ca",
   "metadata": {},
   "source": [
    "### 評估指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe6c4436-1a7f-41d2-b325-4c3e72a9f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top1_acc(labels, pro):\n",
    "    correct = []\n",
    "    for i, p in enumerate(pro):\n",
    "        pred_y = np.argsort(p)[-1]\n",
    "        if int(labels[i]) == pred_y:\n",
    "            correct.append(1)\n",
    "        else:\n",
    "            correct.append(0)\n",
    "    \n",
    "    return round(sum(correct) / len(correct), 4)\n",
    "\n",
    "def top5_acc(labels, pro):\n",
    "    correct = []\n",
    "    for i, p in enumerate(pro):\n",
    "        top5_y = np.argsort(p)[-5:]\n",
    "        if int(labels[i]) in list(top5_y):\n",
    "            correct.append(1)\n",
    "        else:\n",
    "            correct.append(0)\n",
    "    \n",
    "    return round(sum(correct) / len(correct), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd6a9f8-eb0e-4b07-9a1b-ed4e1680d004",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "- sigmoid\n",
    "- [softmax](https://zhuanlan.zhihu.com/p/105722023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d3ef6f-ac2c-485c-8c27-1fa08e435268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sigmoid():\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "    def backward(self, grad):\n",
    "        x = self.x\n",
    "        return grad * self.forward(x) * (1-self.forward(x))\n",
    "\n",
    "class softmax():\n",
    "    def __init__(self):\n",
    "        self.prob = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = np.exp(x)\n",
    "        z = y / np.sum(y, axis=1, keepdims=True)\n",
    "        self.prob = z\n",
    "        return z\n",
    "\n",
    "    def backward(self, y_true):\n",
    "        return self.prob - y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fbabdc-60a5-4ca6-bec5-7b9c44864402",
   "metadata": {},
   "source": [
    "### nn_layer\n",
    "- https://github.com/toxtli/lenet-5-mnist-from-scratch-numpy/blob/master/app.py\n",
    "- ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ad6d5d-7ccc-4406-92aa-3aa4953d679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv():\n",
    "    def __init__(self, input_size, output_size, kernel, stride=1, padding=0, bias=True):\n",
    "        self.input_size = input_size      # input neurons\n",
    "        self.output_size = output_size    # output neurons (#Kernels)\n",
    "        self.kernel = kernel              # kernel size\n",
    "        self.stride = stride              # kernel move size\n",
    "        self.pad = padding            # add extra zero data outside image\n",
    "        \n",
    "        # weight initialization\n",
    "        self.w = {'value': np.random.RandomState(RANDOM_STATE).rand(output_size, input_size, kernel, kernel), 'grad': 0}\n",
    "        # self.w = {'val': np.random.normal(0.0, np.sqrt(2/input_size), (output_size,input_size,F,F)), 'grad': 0}\n",
    "        self.b = {'value': np.random.RandomState(RANDOM_STATE).rand(output_size), 'grad': 0}\n",
    "        self.X = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = np.pad(X, ((0,0),(0,0), (self.pad, self.pad), (self.pad, self.pad)), 'constant')\n",
    "        # N為訓練資料大小, H & W為圖片的向量長寬\n",
    "        (N, input_size, H, W) = X.shape\n",
    "        \n",
    "        # convolution後的圖片向量長寬\n",
    "        CH = int((H + 2*self.pad - self.kernel)/self.stride + 1)\n",
    "        CW = int((W + 2*self.pad - self.kernel)/self.stride + 1)\n",
    "        Y = np.zeros((N, self.output_size, CH, CW))\n",
    "        \n",
    "        \n",
    "        for n in range(N):  # 每筆資料\n",
    "            for c in range(self.output_size):  # 每個kernel\n",
    "                for h in range(CH):\n",
    "                    for w in range(CW):\n",
    "                        # data * weight\n",
    "                        Y[n, c, h, w] = np.sum(X[n, :, h:h+self.kernel, w:w+self.kernel] * self.w['value'][c, :, :, :]) + self.b['value'][c]\n",
    "\n",
    "        self.X = X # backward會用到\n",
    "        return Y\n",
    "\n",
    "    def backward(self, grad):\n",
    "        X = self.X\n",
    "        (N, input_size, H, W) = X.shape\n",
    "        CH = int((H + 2*self.pad - self.kernel)/self.stride + 1)\n",
    "        CW = int((W + 2*self.pad - self.kernel)/self.stride + 1)\n",
    "\n",
    "        dX = np.zeros(X.shape)\n",
    "        dw = np.zeros(self.w['value'].shape)\n",
    "        db = np.zeros(self.b['value'].shape)\n",
    "\n",
    "        # dW\n",
    "        for out in range(self.output_size):\n",
    "            for inp in range(input_size):\n",
    "                for h in range(self.kernel):\n",
    "                    for w in range(self.kernel):\n",
    "                        dw[out, inp, h, w] = np.sum(X[:, inp, h:h+CH, w:w+CW] * grad[:, out, :, :])\n",
    "\n",
    "        # db\n",
    "        for out in range(self.output_size):\n",
    "            db[out] = np.sum(grad[:, out, :, :])\n",
    "        \n",
    "        # dX\n",
    "        W_rot = np.rot90(np.rot90(self.w['value']))\n",
    "        grad_pad = np.pad(grad, ((0,0),(0,0), (self.kernel, self.kernel), (self.kernel, self.kernel)), 'constant')\n",
    "        for n in range(N):\n",
    "            for inp in range(input_size):\n",
    "                for h in range(H):\n",
    "                    for w in range(W):\n",
    "                        dX[n, inp, h, w] = np.sum(W_rot[:, inp, :, :] * grad_pad[n, :, h:h+self.kernel, w:w+self.kernel])\n",
    "\n",
    "        return dX\n",
    "    \n",
    "class maxPool():\n",
    "    def __init__(self, kernel, stride):\n",
    "        self.kernel = kernel\n",
    "        self.stride = stride\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        # if H % 2 == 1:\n",
    "        #     self.ori_shape = True\n",
    "        #     X = np.pad(X, ((0,0),(0,0),(0,1),(0,1)), 'constant')\n",
    "        #     N, C_in, H, W = X.shape\n",
    "        \n",
    "        (N, input_size, H, W) = X.shape\n",
    "        # convolution後的圖片向量長寬\n",
    "        S = self.stride\n",
    "        F = self.kernel\n",
    "        CH = int((H - F)/S + 1)\n",
    "        CW = int((W - F)/S + 1)\n",
    "        Y = np.zeros((N, input_size, CW, CH))\n",
    "        M = np.zeros(X.shape) # mask\n",
    "        \n",
    "        for n in range(N):\n",
    "            for inp in range(input_size):\n",
    "                for h in range(CH):\n",
    "                    for w in range(CW):\n",
    "                        # 回傳kernel內最大值\n",
    "                        Y[n, inp, h, w] = np.max(X[n, inp, h*S:h*S+F, w*S:w*S+F])\n",
    "                        # 將kernel內最大值的index轉化為座標\n",
    "                        i, j = np.unravel_index(X[n, inp, h*S:h*S+F, w*S:w*S+F].argmax(), (F,F))\n",
    "                        M[n, inp, h*S+i, w*S+j] = 1\n",
    "                        \n",
    "        self.mask = M\n",
    "        return Y\n",
    "\n",
    "    def backward(self, grad):\n",
    "        M = self.mask\n",
    "        F = self.kernel\n",
    "        (N, input_size, H, W) = M.shape\n",
    "        grad = np.array(grad)\n",
    "        \n",
    "        # dX\n",
    "        dX = np.zeros(M.shape)\n",
    "        for n in range(N):\n",
    "            for inp in range(input_size):\n",
    "                dX[n, inp, :, :] = grad[n, inp, :, :].repeat(F, axis=0).repeat(F, axis=1)\n",
    "        return dX*M\n",
    "\n",
    "    \n",
    "class FC():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.w = {'value': np.random.RandomState(RANDOM_STATE).rand(input_size, output_size), 'grad': 0}\n",
    "        self.b = {'value': np.random.RandomState(RANDOM_STATE).rand(output_size), 'grad': 0}\n",
    "        self.X = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        return np.dot(X, self.w['value']) + self.b['value']\n",
    "\n",
    "    def backward(self, grad):\n",
    "        X = self.X\n",
    "        dX = np.dot(grad, self.w['value'].T)\n",
    "        self.w['grad'] = np.dot(X.T, grad)\n",
    "        self.b['grad'] = np.sum(grad, axis=0)\n",
    "        # self.update_params()\n",
    "        return dX\n",
    "\n",
    "    def update_params(self, lr=0.001):\n",
    "        self.w['value'] -= lr * self.w['grad']\n",
    "        self.b['value'] -= lr * self.b['grad']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53451a50-563b-4e5e-b8fe-d19004ca1385",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef7d2d44-9faf-470b-981a-eb38fc704500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossEntropy(y_pred, y_true):\n",
    "    # np.seterr(divide = 'ignore')\n",
    "    loss = -np.sum(np.multiply(y_true , np.log(y_pred)))\n",
    "    # loss = -np.sum(np.multiply(y_true , np.log(y_pred, where=y_pred>0)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31bf0ed-e2a9-42de-9cf6-6f28dfd0cdfc",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "- [SGDMomentum](https://www.sciencedirect.com/topics/engineering/momentum-coefficient)\n",
    "- velocity = momentum * velocity + (1 - momentum) * gradient\n",
    "- weight = weight - (learning_rate * velocity + regularization * weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0a456af-5172-4c2a-9a01-3c8092173089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDMomentum():\n",
    "    def __init__(self, params, lr, momentum, reg):\n",
    "        self.len = len(params)\n",
    "        self.parameters = params\n",
    "        self.velocities = []\n",
    "        \n",
    "        for param in self.parameters:\n",
    "            self.velocities.append(np.zeros(param['value'].shape))\n",
    "            \n",
    "        self.lr = lr\n",
    "        # Momentum coefficient: A parameter between 0 and 1 used to increase the rate at which the weight factors are adjusted\n",
    "        self.momentum = momentum  \n",
    "        # the L2 regularization coefficient\n",
    "        self.reg = reg\n",
    "\n",
    "    def step(self):\n",
    "        for i in range(self.len):\n",
    "            self.velocities[i] = self.momentum * self.velocities[i] + (1 - self.momentum) * self.parameters[i]['grad']  \n",
    "            self.parameters[i]['value'] -= (self.lr * self.velocities[i] + self.reg * self.parameters[i]['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb307f70-507d-441a-b41c-ca3db7ff46e5",
   "metadata": {},
   "source": [
    "### LeNet5\n",
    "- https://github.com/toxtli/lenet-5-mnist-from-scratch-numpy/blob/master/app.py\n",
    "- ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7781b0be-62b3-4556-b217-ccfa9ec31575",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5():\n",
    "    def __init__(self):\n",
    "        self.conv1  = conv(1, 6, 5)\n",
    "        self.sigmoid1 = sigmoid()\n",
    "        self.pool1 = maxPool(2, 2)\n",
    "        self.conv2 = conv(6, 16, 5)\n",
    "        self.sigmoid2 = sigmoid()\n",
    "        self.pool2 = maxPool(2,2)\n",
    "        self.FC1 = FC(16*5*5, 120)\n",
    "        self.sigmoid3 = sigmoid()\n",
    "        self.FC2 = FC(120, 84)\n",
    "        self.sigmoid4 = sigmoid()\n",
    "        self.FC3 = FC(84, 50)\n",
    "        self.softmax = softmax()\n",
    "        \n",
    "        self.p2_shape = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.conv1.forward(x)\n",
    "        a1 = self.sigmoid1.forward(h1)\n",
    "        p1 = self.pool1.forward(a1)\n",
    "        \n",
    "        h2 = self.conv2.forward(p1)\n",
    "        a2 = self.sigmoid2.forward(h2)\n",
    "        p2 = self.pool2.forward(a2)\n",
    "        self.p2_shape = p2.shape\n",
    "        \n",
    "        fl = p2.reshape(x.shape[0], -1) # Flatten\n",
    "        h3 = self.FC1.forward(fl)\n",
    "        a3 = self.sigmoid3.forward(h3)\n",
    "        h4 = self.FC2.forward(a3)\n",
    "        a4 = self.sigmoid4.forward(h4)\n",
    "        h5 = self.FC3.forward(a4)\n",
    "        a5 = self.softmax.forward(h5)\n",
    "        return a5\n",
    "    \n",
    "    def backward(self, grad):\n",
    "        grad = self.FC3.backward(grad)\n",
    "        grad = self.sigmoid4.backward(grad)\n",
    "        grad = self.FC2.backward(grad)\n",
    "        grad = self.sigmoid3.backward(grad)\n",
    "        grad = self.FC1.backward(grad)\n",
    "        \n",
    "        grad = grad.reshape(self.p2_shape) # reshape\n",
    "        grad = self.pool2.backward(grad)\n",
    "        grad = self.sigmoid2.backward(grad)\n",
    "        grad = self.conv2.backward(grad)\n",
    "        \n",
    "        grad = self.pool1.backward(grad)\n",
    "        grad = self.sigmoid1.backward(grad)\n",
    "        grad = self.conv1.backward(grad)\n",
    "        \n",
    "    def get_params(self):\n",
    "        return [self.conv1.w, self.conv1.b, self.conv2.w, self.conv2.b, self.FC1.w,\n",
    "                self.FC1.b, self.FC2.w, self.FC2.b, self.FC3.w, self.FC3.b]\n",
    "\n",
    "    def set_params(self, params):\n",
    "        [self.conv1.w, self.conv1.b, self.conv2.w, self.conv2.b, self.FC1.w, \n",
    "         self.FC1.b, self.FC2.w, self.FC2.b, self.FC3.w, self.FC3.b] = params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49098e24-8bcc-4d8f-a04d-d1ae487a7e7c",
   "metadata": {},
   "source": [
    "### Improved LeNet5\n",
    "- Activation function: x = Sigmoid(x) ==> x = x*sigmoid(x)<br>dy/dx = sigmoid(x) + x * sigmoid'(x);   sigmoid'(x) = sigmoid(x) * (1 - sigmoid(x))\n",
    "- kernel size: 5x5 ==> 3x3\n",
    "- Increase one convolution layer to LeNet5 (any position)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cfd359f-2fdc-4155-8a56-dbeddfa54e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedLeNet5():\n",
    "    def __init__(self):\n",
    "        self.conv1  = conv(1, 5, 3)\n",
    "        self.sigmoid1 = sigmoid()\n",
    "        self.pool1 = maxPool(2, 2)\n",
    "        self.conv2 = conv(5, 10, 3) # new conv layer\n",
    "        self.sigmoid2 = sigmoid()\n",
    "        self.pool2 = maxPool(2,2)\n",
    "        self.conv3 = conv(10, 16, 3)\n",
    "        self.sigmoid3 = sigmoid()\n",
    "        self.pool3 = maxPool(2,2)\n",
    "        self.FC1 = FC(16*3*3, 120)\n",
    "        self.sigmoid4 = sigmoid()\n",
    "        self.FC2 = FC(120, 84)\n",
    "        self.sigmoid5 = sigmoid()\n",
    "        self.FC3 = FC(84, 50)\n",
    "        self.softmax = softmax()\n",
    "        \n",
    "        self.p3_shape = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.conv1.forward(x)\n",
    "        a1 = self.sigmoid1.forward(h1)\n",
    "        a11 = self.a1 * self.h1\n",
    "        p1 = self.pool1.forward(a11)\n",
    "        \n",
    "        h2 = self.conv2.forward(p1)\n",
    "        a2 = self.sigmoid2.forward(h2)\n",
    "        a21 = self.a2 * self.h2\n",
    "        p2 = self.pool2.forward(a21)\n",
    "        \n",
    "        h3 = self.conv3.forward(p2)\n",
    "        a3 = self.sigmoid3.forward(h3)\n",
    "        a31 = self.a3 * self.h3\n",
    "        p3 = self.pool3.forward(a31)\n",
    "        self.p3_shape = p3.shape\n",
    "        \n",
    "        fl = p3.reshape(x.shape[0], -1) # Flatten\n",
    "        h4 = self.FC1.forward(fl)\n",
    "        a4 = self.sigmoid4.forward(h4)\n",
    "        a41 = self.a4 * self.h4\n",
    "        \n",
    "        h5 = self.FC2.forward(a41)\n",
    "        a5 = self.sigmoid5.forward(h5)\n",
    "        a51 = self.a5 * self.h5\n",
    "        \n",
    "        h6 = self.FC3.forward(a51)\n",
    "        a6 = self.softmax.forward(h6)\n",
    "        return a6\n",
    "    \n",
    "    def backward(self, grad):\n",
    "        # dy/dx = sigmoid(x) + x * sigmoid'(x)\n",
    "        grad = self.FC3.backward(grad) \n",
    "        grad1 = grad * self.a5   # sigmoid(x)\n",
    "        grad2 = self.sigmoid5.backward(grad * self.h5) # x * sigmoid'(x)\n",
    "        grad = grad1 + grad2\n",
    "        \n",
    "        grad = self.FC2.backward(grad)\n",
    "        grad1 = grad * self.a4   \n",
    "        grad2 = self.sigmoid4.backward(grad * self.h4) \n",
    "        grad = grad1 + grad2\n",
    "        \n",
    "        grad = self.FC1.backward(grad)\n",
    "        grad = grad.reshape(self.p3_shape)\n",
    "        \n",
    "        grad = self.pool3.backward(grad)\n",
    "        grad1 = grad * self.a3   \n",
    "        grad2 = self.sigmoid3.backward(grad * self.h3) \n",
    "        grad = grad1 + grad2\n",
    "        grad = self.conv3.backward(grad)\n",
    "        \n",
    "        grad = self.pool2.backward(grad)\n",
    "        grad1 = grad * self.a2   \n",
    "        grad2 = self.sigmoid2.backward(grad * self.h2) \n",
    "        grad = grad1 + grad2\n",
    "        grad = self.conv2.backward(grad)\n",
    "        \n",
    "        grad = self.pool1.backward(grad)\n",
    "        grad1 = grad * self.a1   \n",
    "        grad2 = self.sigmoid1.backward(grad * self.h1) \n",
    "        grad = grad1 + grad2\n",
    "        grad = self.conv1.backward(grad)\n",
    "        \n",
    "    def get_params(self):\n",
    "        return [self.conv1.w, self.conv1.b, self.conv2.w, self.conv2.b, self.conv3.w, self.conv3.b,\n",
    "                self.FC1.w, self.FC1.b, self.FC2.w, self.FC2.b, self.FC3.w, self.FC3.b]\n",
    "\n",
    "    def set_params(self, params):\n",
    "        [self.conv1.w, self.conv1.b, self.conv2.w, self.conv2.b, self.conv3.w, self.conv3.b,\n",
    "         self.FC1.w, self.FC1.b, self.FC2.w, self.FC2.b, self.FC3.w, self.FC3.b] = params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd6f69-e49a-4b83-b5e5-db5adc1128b0",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6ca2eeb-7e67-44d3-aac0-c682c04a0f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_LeNet5():\n",
    "    def __init__(self, batch, epoch, model):\n",
    "        self.epoch = epoch\n",
    "        self.batch = batch\n",
    "        self.model = model\n",
    "        self.optim = SGDMomentum(self.model.get_params(), lr=1e-4, momentum=0.8, reg=3e-4)\n",
    "        \n",
    "    def train(self, X_train, Y_train, X_val, Y_val):\n",
    "        X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2])\n",
    "        X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1], X_val.shape[2])\n",
    "        \n",
    "        loss_list = []\n",
    "        loss_batch_list = []\n",
    "        for epoch in range(self.epoch):\n",
    "            print(f'----------Epoch {epoch+1}----------')\n",
    "            train_acc = 0\n",
    "            train_top5_acc = 0\n",
    "            train_loss = 0\n",
    "            for i in range(0, len(X_train), self.batch):\n",
    "                if i % (10*self.batch) == 0 and i != 0:\n",
    "                    train_time = i / self.batch\n",
    "                    train_batch_acc = train_acc / train_time\n",
    "                    train_batch_top5_acc = train_top5_acc / train_time\n",
    "                    train_batch_loss = train_loss / train_time\n",
    "                    loss_list.append([train_batch_acc, train_batch_top5_acc, train_batch_loss])\n",
    "                    print(f\"Batch {int(train_time)}： train_acc: {train_batch_acc:.4f} ｜ train_top5_acc: {train_batch_top5_acc:.4f} | train_loss: {train_batch_loss:.4f}\")\n",
    "                    \n",
    "                X_batch = X_train[i: i + self.batch]\n",
    "                Y_batch = Y_train[i: i + self.batch]\n",
    "                probs = self.model.forward(X_batch)\n",
    "                # upstream gradient\n",
    "                grad = probs - Y_batch\n",
    "                self.model.backward(grad)\n",
    "                self.optim.step()\n",
    "                \n",
    "                # Evaluate the accuracy and loss\n",
    "                train_acc += accuracy_score(np.argmax(Y_batch, axis=1), np.argmax(probs, axis=1))\n",
    "                train_top5_acc += top5_acc(np.argmax(Y_batch, axis=1), probs)\n",
    "                train_loss += CrossEntropy(probs, Y_batch)\n",
    "                \n",
    "            # 計算平均準確率及訓練損失\n",
    "            train_time = math.ceil(len(X_train)/self.batch)\n",
    "            train_acc = train_acc / train_time\n",
    "            train_top5_acc = train_top5_acc / train_time\n",
    "            train_loss = train_loss / train_time\n",
    "            \n",
    "            # 計算驗證準確率及損失\n",
    "            val_probs = self.model.forward(X_val)\n",
    "            val_acc =  accuracy_score(np.argmax(Y_val, axis=1), np.argmax(val_probs, axis=1))\n",
    "            val_top5_acc = top5_acc(np.argmax(Y_val, axis=1), val_probs)\n",
    "            val_loss = CrossEntropy(val_probs, Y_val)\n",
    "            \n",
    "            loss_list.append([train_acc, train_top5_acc, train_loss, val_acc, val_top5_acc, val_loss])\n",
    "            print(f\"Epoch {epoch+1}： train_acc: {train_acc:.4f} | train_loss: {train_loss:.4f} | val_acc: {val_acc:.4f} | val_loss: {val_loss:.4f}\")\n",
    "            \n",
    "        return loss_list, loss_batch_list\n",
    "    \n",
    "    def predict(self, X_test, Y_test):\n",
    "        test_probs = self.model.forward(X_test)\n",
    "        test_acc = accuracy_score(np.argmax(Y_test, axis=1), np.argmax(test_probs, axis=1))\n",
    "        test_top5_acc = top5_acc(np.argmax(Y_test, axis=1), test_probs)\n",
    "        test_loss = CrossEntropy(test_probs, Y_test)\n",
    "        print(f\"\\nTest：\\ntest_acc: {test_acc:.4f} | test_top5_acc: {test_top5_acc:.4f} | test_loss: {test_loss:.4f}\")\n",
    "        return [test_acc, test_top5_acc, test_loss]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f221497-ca11-4a5f-82ff-cddeab7ea1dc",
   "metadata": {},
   "source": [
    "### result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aeb97f6-f00e-46c8-bd3e-1973ba5aab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class plot():\n",
    "    def __init__(self, result):\n",
    "        self.result = result\n",
    "        self.plot_acc()\n",
    "        self.plot_top5_acc()\n",
    "        self.plot_loss()\n",
    "        \n",
    "    def plot_acc(self):\n",
    "        plt.plot([x[0] for x in self.result])\n",
    "        plt.plot([x[3] for x in self.result])\n",
    "        plt.title('Top1 Accuracy History')\n",
    "        plt.ylabel('Top1 Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.savefig(\"top5_acc.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_top5_acc(self):\n",
    "        plt.plot([x[1] for x in self.result])\n",
    "        plt.plot([x[4] for x in self.result])\n",
    "        plt.title('Top5 Accuracy History')\n",
    "        plt.ylabel('Top5 Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.savefig(\"top5_acc.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.plot([x[2] for x in self.result])\n",
    "        plt.plot([x[5] for x in self.result])\n",
    "        plt.title('Loss History')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.savefig(\"loss.png\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66647a9d-8534-43cd-83b4-0a38b1ae0752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Epoch 1----------\n",
      "Batch 10： train_acc: 0.0196 ｜ train_top5_acc: 0.1006 | train_loss: 5464.6227\n",
      "Batch 20： train_acc: 0.0199 ｜ train_top5_acc: 0.0991 | train_loss: 4886.8011\n",
      "Batch 30： train_acc: 0.0198 ｜ train_top5_acc: 0.0995 | train_loss: 4589.5477\n",
      "Batch 40： train_acc: 0.0202 ｜ train_top5_acc: 0.0995 | train_loss: 4421.1214\n",
      "Batch 50： train_acc: 0.0201 ｜ train_top5_acc: 0.0988 | train_loss: 4319.6659\n",
      "Batch 60： train_acc: 0.0198 ｜ train_top5_acc: 0.0977 | train_loss: 4251.6670\n",
      "Epoch 1： train_acc: 0.0197 | train_loss: 4189.0553 | val_acc: 0.0200 | val_loss: 1762.7380\n",
      "----------Epoch 2----------\n",
      "Batch 10： train_acc: 0.0196 ｜ train_top5_acc: 0.0966 | train_loss: 3912.1741\n",
      "Batch 20： train_acc: 0.0191 ｜ train_top5_acc: 0.0963 | train_loss: 3912.4555\n",
      "Batch 30： train_acc: 0.0195 ｜ train_top5_acc: 0.0965 | train_loss: 3912.4588\n",
      "Batch 40： train_acc: 0.0202 ｜ train_top5_acc: 0.0987 | train_loss: 3912.1091\n"
     ]
    }
   ],
   "source": [
    "#LeNet5\n",
    "LeNet5 = train_LeNet5(BATCH_SIZE, EPOCHS, LeNet5())\n",
    "LeNet5_train, LeNet5_batch = LeNet5.train(X_train, Y_train, X_val, Y_val)\n",
    "LeNet5_test = LeNet5.predict(X_test, Y_test)\n",
    "plot(LeNet5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcab405-cc05-4076-92d0-02a994084ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved LeNet5\n",
    "Improved_LeNet5 = train_LeNet5(BATCH_SIZE, EPOCHS, ImprovedLeNet5())\n",
    "Improved_LeNet5_train, Improved_LeNet5_batch = LeNet5.train(X_train, Y_train, X_val, Y_val)\n",
    "Improved_LeNet5_test = LeNet5.predict(X_test, Y_test)\n",
    "plot(Improved_LeNet5_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
