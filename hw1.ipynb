{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.io import imread\n",
    "from skimage.filters import prewitt_h,prewitt_v\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = './data/'\n",
    "\n",
    "train, train_labels = [], []\n",
    "with open(dir_path + 'train.txt', 'r') as f:\n",
    "  for line in f:\n",
    "    data = line.split(\" \")\n",
    "    train.append(dir_path + data[0])\n",
    "    train_labels.append(data[1].replace('\\n', ''))\n",
    "\n",
    "\n",
    "val, val_labels = [], []\n",
    "with open(dir_path + 'val.txt', 'r') as f:\n",
    "  for line in f:\n",
    "    data = line.split(\" \")\n",
    "    val.append(dir_path + data[0])\n",
    "    val_labels.append(data[1].replace('\\n', ''))\n",
    "\n",
    "\n",
    "test, test_labels = [], []\n",
    "with open(dir_path + 'test.txt', 'r') as f:\n",
    "  for line in f:\n",
    "    data = line.split(\" \")\n",
    "    test.append(dir_path + data[0])\n",
    "    test_labels.append(data[1].replace('\\n', ''))\n",
    "\n",
    "print(f'訓練資料共{len(train)}筆')\n",
    "print(f'驗證資料共{len(val)}筆')\n",
    "print(f'測試資料共{len(test)}筆')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction (硬體關係跑不動，因此後來沒使用)\n",
    "- [bovw](https://tigercosmos.xyz/post/2020/06/cv/bag-of-visual-words/)\n",
    "- [bovw_github](https://gist.github.com/tigercosmos/a5af5359b81b99669ef59e82839aed60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(paths, cluster_size):\n",
    "    bag_of_features = []\n",
    "    # tqdm(images.items()):\n",
    "    for path in tqdm(paths):   \n",
    "        # 讀取image，並轉為灰階影像\n",
    "        img = cv2.imread(path, 0)\n",
    "        # 利用sift找到圖片的關鍵點\n",
    "        sift = cv2.SIFT_create()                \n",
    "        keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "\n",
    "        if descriptors is not None:\n",
    "            for des in descriptors:\n",
    "                bag_of_features.append(des)\n",
    "\n",
    "    clusters = KMeans(cluster_size).fit(np.array(bag_of_features).astype('float32'))\n",
    "\n",
    "    return clusters\n",
    "\n",
    "# labels共50個\n",
    "# feature_clusters = get_clusters(train, 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[edgeDetection](https://kknews.cc/zh-tw/code/y5a5v3g.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(paths):\n",
    "    features = []\n",
    "    for path in tqdm(paths):\n",
    "        # 讀取image，並轉為灰階影像\n",
    "        image = imread(path, as_gray=True) \n",
    "        # 為image生成邊緣特徵\n",
    "        edges_prewitt_horizontal = prewitt_h(image) \n",
    "        edges_prewitt_vertical = prewitt_v(edges_prewitt_horizontal) \n",
    "        # 最大特徵長度   \n",
    "        max_len = 100000  \n",
    "         # 轉成一維陣列\n",
    "        edge_features = edges_prewitt_vertical.flatten()\n",
    "        if len(edge_features) < max_len:\n",
    "            pad_features = np.pad(edge_features, (0, max_len-len(edge_features)), 'constant', constant_values=0)\n",
    "            features.append(pad_features)\n",
    "        else:\n",
    "            features.append(edge_features[0: max_len])\n",
    "            \n",
    "    return features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料前處理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(paths):\n",
    "    features = []\n",
    "    for path in tqdm(paths):\n",
    "        # 讀取image，並轉為灰階影像\n",
    "        image = cv2.imread(path, 0)\n",
    "        # 灰階圖片數值介於0~255之間\n",
    "        image_normalize = image/255\n",
    "        # 最大特徵長度   \n",
    "        max_len = 100000  \n",
    "        # 轉成一維陣列\n",
    "        image_features = image_normalize.flatten()\n",
    "        if len(image_features) < max_len:\n",
    "            pad_features = np.pad(image_features, (0, max_len-len(image_features)), 'constant', constant_values=0)\n",
    "            features.append(pad_features)\n",
    "        else:\n",
    "            features.append(image_features[0: max_len])\n",
    "            \n",
    "    return features\n",
    "\n",
    "train_features = data_preprocessing(train)\n",
    "val_features = data_preprocessing(val)\n",
    "test_features = data_preprocessing(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練模型、驗證模型與預測模型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html#sklearn.linear_model.Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# split the data \n",
    "# x_train, x_test, y_train, y_test = train_test_split(train_features[0:5000], train_labels[0:5000], test_size=0.2, random_state=0)\n",
    "\n",
    "# train Perceptron classifier\n",
    "clf = Perceptron()\n",
    "clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('Perceptron Classifier')\n",
    "# valid Perceptron classifier\n",
    "y_val = clf.predict(val_features)\n",
    "val_accuracy = accuracy_score(val_labels, y_val)\n",
    "print(f'validation_data_accuracy:{val_accuracy}')\n",
    "\n",
    "# test Perceptron classifier\n",
    "y_test = clf.predict(test_features)\n",
    "test_accuracy = accuracy_score(test_labels, y_test)\n",
    "print(f'test_data_accuracy:{test_accuracy}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [SVM](https://scikit-learn.org/stable/modules/svm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# train SVM classifier\n",
    "svm = SVC(kernel='linear', random_state=0)\n",
    "svm.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('SVM Classifier')\n",
    "# valid SVM classifier\n",
    "y_val = svm.predict(val_features)\n",
    "val_accuracy = accuracy_score(val_labels, y_val)\n",
    "print(f'validation_data_accuracy:{val_accuracy}')\n",
    "\n",
    "# test SVM classifier\n",
    "y_test = svm.predict(test_features)\n",
    "test_accuracy = accuracy_score(test_labels, y_test)\n",
    "print(f'test_data_accuracy:{test_accuracy}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# train AdaBoost classifier\n",
    "Ada = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "Ada = Ada.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('Adaoost Classifier')\n",
    "# valid Adaoost classifier\n",
    "y_val = Ada.predict(val_features)\n",
    "val_accuracy = accuracy_score(val_labels, y_val)\n",
    "print(f'validation_data_accuracy:{val_accuracy}')\n",
    "\n",
    "# test Adaoost classifier\n",
    "y_test = Ada.predict(test_features)\n",
    "test_accuracy = accuracy_score(test_labels, y_test)\n",
    "print(f'test_data_accuracy:{test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
